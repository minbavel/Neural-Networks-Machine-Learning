{"cells":[{"metadata":{},"cell_type":"markdown","source":"This  CIFAR-100 dataset consists of 60000 32x32 colour images. It has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 super classes.\n\nHere I implement a resnet model from this paper (https://arxiv.org/abs/1512.03385) in Keras. \nThis model generates about 0.27M parameters"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport keras\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom keras.layers import AveragePooling2D, Input, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.datasets import cifar100\nimport numpy as np\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After experimenting with different number of epochs, \nI chose 200 where the accuracy stabilizes and we implement the depth as 20 as described in the paper."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"batch_size = 32\nepochs = 200\ndata_augmentation = True\nnum_classes = 100\nsubtract_pixel_mean = True\ndepth = 20","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here I load and normalize the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = cifar100.load_data()\ninput_shape = x_train.shape[1:]\nx_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\n\nif subtract_pixel_mean:\n    x_train_mean = np.mean(x_train, axis=0)\n    x_train -= x_train_mean\n    x_test -= x_train_mean\n\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\nprint('y_train shape:', y_train.shape)\n\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a learning rate scheduler which is used to decay the learning rate as the training progresses in order to prevent plateaus."},{"metadata":{"trusted":true},"cell_type":"code","source":"def lr_schedule(epoch):\n    lr = 1e-3\n    if epoch > 180:\n        lr *= 0.5e-3\n    elif epoch > 160:\n        lr *= 1e-3\n    elif epoch > 120:\n        lr *= 1e-2\n    elif epoch > 80:\n        lr *= 1e-1\n    print('Learning rate: ', lr)\n    return lr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here I model the Resnet as described in the paper."},{"metadata":{"trusted":true},"cell_type":"code","source":"def resnet_layer(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation='relu',\n                 batch_normalization=True,\n                 conv_first=True):\n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resnet(input_shape, depth, num_classes=100):\n    if (depth - 2) % 6 != 0:\n        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n    num_filters = 16\n    num_res_blocks = int((depth - 2) / 6)\n\n    inputs = Input(shape=input_shape)\n    x = resnet_layer(inputs=inputs)\n    for stack in range(3):\n        for res_block in range(num_res_blocks):\n            strides = 1\n            if stack > 0 and res_block == 0:\n                strides = 2\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters,\n                             strides=strides)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters,\n                             activation=None)\n            if stack > 0 and res_block == 0:\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = keras.layers.add([x, y])\n            x = Activation('relu')(x)\n        num_filters *= 2\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation='softmax',\n                    kernel_initializer='he_normal')(y)\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\nmodel = resnet(input_shape=input_shape, depth=depth)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(lr=lr_schedule(0)),\n              metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, I implement data augmentation to generate data variations to train the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_scheduler = LearningRateScheduler(lr_schedule)\n\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\n\ncallbacks = [lr_reducer, lr_scheduler]\nif not data_augmentation:\n    print('Not using data augmentation.')\n    model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True,\n              callbacks=callbacks)\nelse:\n    print('Using real-time data augmentation.')\n    datagen = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        zca_epsilon=1e-06,\n        rotation_range=0,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        shear_range=0.,\n        zoom_range=0.,\n        channel_shift_range=0.,\n        fill_mode='nearest',\n        cval=0.,\n        horizontal_flip=True,\n        vertical_flip=False,\n        rescale=None,\n        preprocessing_function=None,\n        data_format=None,\n        validation_split=0.0)\n    datagen.fit(x_train)\n    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n                        validation_data=(x_test, y_test),\n                        epochs=epochs, verbose=2, workers=4,\n                        callbacks=callbacks,steps_per_epoch=x_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(x_test, y_test, verbose=2)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}