{"cells":[{"metadata":{},"cell_type":"markdown","source":"Caltech 256 is just like the Caltech 101 dataset except it has 256 classes containing a total of 30607 images."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom os import listdir\nfrom glob import glob\nimport itertools\nimport fnmatch\nimport random\nfrom PIL import Image\nimport zlib\nimport itertools\nimport csv\nfrom tqdm import tqdm\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport cv2\nimport skimage\nfrom skimage import transform\nfrom skimage.transform import resize\nimport scipy\nfrom scipy.misc import imresize, imread\nfrom scipy import misc\nimport keras\nfrom keras import backend as K\nfrom keras import models, layers, optimizers\nfrom keras.applications import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.models import Model, Sequential, model_from_json\nfrom keras.layers import Dense, Dropout, Input, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D, Lambda, AveragePooling2D\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\nimport sklearn\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\nfrom sklearn.utils import class_weight\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here I load, preprocess and sample the image data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"def loadBatchImages(path,nSamples,nVal):\n    catList = listdir(path)\n    loadedImagesTrain = []\n    loadedLabelsTrain = []\n    loadedImagesVal = []\n    loadedLabelsVal = []\n    for cat in catList[0:256]:\n        deepPath = path+cat+\"/\"\n        imageList = listdir(deepPath)\n        indx = 0\n        for images in imageList[0:nSamples + nVal]:                \n            img = load_img(deepPath + images)\n            img = img_to_array(img)\n            img = misc.imresize(img, (224,224))\n            if indx < nSamples:\n                loadedLabelsTrain.append(int(images[0:3])-1)\n                loadedImagesTrain.append(img)\n            else:\n                loadedLabelsVal.append(int(images[0:3])-1)\n                loadedImagesVal.append(img)\n            indx += 1\n    return loadedImagesTrain, np_utils.to_categorical(loadedLabelsTrain), loadedImagesVal, np_utils.to_categorical(loadedLabelsVal) \n\ndef shuffledSet(a, b):\n    assert np.shape(a)[0] == np.shape(b)[0]\n    p = np.random.permutation(np.shape(a)[0])\n    return (a[p], b[p])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here I used train sample size as 10 and validation sample size as 7 because of kaggle Memory limit"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/caltech256-without-rename2/256_objectcategories/256_ObjectCategories/'\nnSamples = 10\nnVal = 7  \ndata, labels, dataVal, labelsVal = loadBatchImages(path,nSamples,nVal)\ndata = preprocess_input(np.float64(data))\ndataVal = preprocess_input(np.float64(dataVal))\ntrain = shuffledSet(np.asarray(data),labels)\nval = shuffledSet(np.asarray(dataVal),labelsVal)\nX_train = train[0]\ny_train = train[1]\nX_test = val[0]\ny_test = val[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here I loaded the pretrained model weights for the VGG16 model and Evaluating the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weight1 = None\nweight_path1 = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model = VGG16(weights = weight_path1, include_top=False, input_shape=(224, 224, 3))\noptimizer1 = keras.optimizers.RMSprop(lr=0.0001)\n\ndef vggModelWithNoTop(xtrain,ytrain,xtest,ytest,pretrainedmodel,pretrainedweights,classweight,numclasses,numepochs,optimizer,labels):\n    base_model = pretrained_model \n    x = base_model.output\n    x = Conv2D(256, kernel_size = (3,3), padding = 'valid')(x)\n    x = Flatten()(x)\n    x = Dropout(0.75)(x)\n    predictions = Dense(numclasses, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    for layer in base_model.layers:\n        layer.trainable = False\n    model.compile(loss='categorical_crossentropy', \n                  optimizer=optimizer, \n                  metrics=['accuracy'])\n    model.summary()\n    #Here I Train the Model\n    history = model.fit(xtrain,ytrain, epochs=numepochs, validation_data=(xtest,ytest), verbose=2)\n    #Here I Evaluate the model\n    score = model.evaluate(xtest,ytest, verbose=0)\n    print('\\nTest loss  :', score[0])\n    print('Test Accuracy:', score[1])\n    y_pred = model.predict(xtest)\n    return model\nvggModelWithNoTop(X_train, y_train, X_test, y_test,pretrained_model,weight_path1,class_weight1,257,600,optimizer1,labels)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}